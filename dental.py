# -*- coding: utf-8 -*-
"""Dental.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r3cv3xjA-3fAEPneJ8EKZ3iXKOCfDs8R
"""

#!pip install ultralytics

from ultralytics import YOLO
import os
import shutil
import random

image_dir = "/content/drive/MyDrive/Shirsh Barnwal_Dental/images"
label_dir = "/content/drive/MyDrive/Shirsh Barnwal_Dental/labels"
output_dir = "/content/drive/MyDrive/Shirsh_Barnwal_Dental/dataset"

for split in ["train", "val", "test"]:
    os.makedirs(os.path.join(output_dir, "images", split), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "labels", split), exist_ok=True)

image_files = [f for f in os.listdir(image_dir) if f.endswith(".jpg")]
random.shuffle(image_files)

train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1
n_total = len(image_files)
n_train = int(n_total * train_ratio)
n_val = int(n_total * val_ratio)

train_files = image_files[:n_train]
val_files = image_files[n_train:n_train + n_val]
test_files = image_files[n_train + n_val:]

#This to separate the given folders of images and labels into a new directory 'dataset' and create two folders in it called images and labels, and they themselves are split into folders - train,val,test

"""def move_files(files, split):
    for f in files:
        img_src = os.path.join(image_dir, f)
        lbl_src = os.path.join(label_dir, f.replace(".jpg", ".txt"))

        img_dst = os.path.join(output_dir, "images", split, f)
        lbl_dst = os.path.join(output_dir, "labels", split, f.replace(".jpg", ".txt"))

        shutil.copy(img_src, img_dst)
        if os.path.exists(lbl_src):
            shutil.copy(lbl_src, lbl_dst)

# Move files
move_files(train_files, "train")
move_files(val_files, "val")
move_files(test_files, "test")

print(f"Split into {len(train_files)} images in training set, {len(val_files)} images in validation set, and {len(test_files)} images in test set.")"""

!cat /content/drive/MyDrive/Shirsh_Barnwal_Dental/dental.yaml

model = YOLO("yolov8s.pt")

model.train(
    data="/content/drive/MyDrive/Shirsh_Barnwal_Dental/dataset/dental.yaml",
    epochs=50,
    imgsz=640,
    batch=16
)

model = YOLO("runs/detect/train3/weights/best.pt")

results = model.val(data="/content/drive/MyDrive/Shirsh_Barnwal_Dental/dataset/dental.yaml",
                    split="test",
                    save_json=True,
                    plots=True)

print("Class-wise Metrics:\n")

#This code snippet prints the percision,recall,mAP@50 and mAP@50-95 for each of the 32 classes

for class_id, class_name in results.names.items():
    precision = results.box.p[class_id]   # precision per class
    recall = results.box.r[class_id]      # recall per class
    map50 = results.box.ap50[class_id]    # mAP@50 per class
    map5095 = results.box.ap[class_id]    # mAP@50-95 per class

    print(f"Class {class_id} ({class_name}):")
    print(f"  Precision: {precision:.3f}")
    print(f"  Recall:    {recall:.3f}")
    print(f"  mAP@50:    {map50:.3f}")
    print(f"  mAP@50-95: {map5095:.3f}\n")

import matplotlib.pyplot as plt
import seaborn as sns

cm = results.confusion_matrix.matrix  # confusion matrix as numpy array
class_names = list(results.names.values())

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt=".0f", xticklabels=class_names, yticklabels=class_names, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

results = model.predict(
    source="/content/drive/MyDrive/Shirsh_Barnwal_Dental/dataset/images/test",
    conf=0.25,  # confidence threshold
    save=True   # saves images with boxes in runs/detect/predict
)

# Display a few predictions inline
for r in results[:5]:  # show first 5 test images
    im_bgr = r.plot()  # plotted image (with boxes + FDI IDs)
    im_rgb = im_bgr[:, :, ::-1]
    plt.figure(figsize=(6,6))
    plt.imshow(im_rgb)
    plt.axis("off")
    plt.show()

import cv2

img_path = "/content/runs/detect/train3/results.png"
#These results are given by the YOLOv8 model itself

img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(12,6))
plt.imshow(img)
plt.axis("off")
plt.title("Training Curves (Loss / mAP / Precision / Recall)")
plt.show()

xyxy

import numpy as np

#Splits the pictures of the teeth into two horizontal pics, with line being y = Median of y coordinates of all detection centres

def split_upper_lower(detections):
    centers_y = [ ( (xyxy[1] + xyxy[3]) / 2 ) for xyxy in detections ]
    median_y = np.median(centers_y)
    upper = [d for d in detections if ( (d[0][1] + d[0][3]) / 2 ) < median_y]
    lower = [d for d in detections if ( (d[0][1] + d[0][3]) / 2 ) >= median_y]
    return upper, lower

def split_left_right(detections):
    centers_x = [ ( (xyxy[0] + xyxy[2]) / 2 ) for xyxy in detections ]
    mid_x = np.median(centers_x)
    left = [d for d in detections if ( (d[0][0] + d[0][2]) / 2 ) < mid_x]
    right = [d for d in detections if ( (d[0][0] + d[0][2]) / 2 ) >= mid_x]
    return left, right

def assign_fdi(quadrant_detections, base_id):
    quadrant_detections = sorted(quadrant_detections, key=lambda d: (d[0][0] + d[0][2]) / 2)
    assigned = {}
    for i, det in enumerate(quadrant_detections, start=1):
        assigned[tuple(det[0])] = base_id + (i-1)
    return assigned

def detect_missing_teeth(quadrant_detections, base_id):
    centers = [ ( (xyxy[0] + xyxy[2]) / 2 ) for xyxy, _ in quadrant_detections ]
    avg_gap = np.mean(np.diff(sorted(centers)))
    assigned = {}
    fdi = base_id
    for i in range(len(centers)-1):
        assigned[tuple(quadrant_detections[i][0])] = fdi
        fdi += 1
        if (centers[i+1] - centers[i]) > 1.5 * avg_gap:  # large gap = missing tooth
            fdi += 1  # skip one
    assigned[tuple(quadrant_detections[-1][0])] = fdi
    return assigned

import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2

# Example detections format:
# [( (x1, y1, x2, y2), conf ), ... ]
# (you would replace this with YOLO model outputs)
detections = [
    ((100, 120, 150, 180), 0.95),
    ((160, 125, 210, 185), 0.92),
    ((300, 130, 350, 190), 0.90),
    ((400, 135, 450, 195), 0.88),
]

# Example corrected FDI assignments after post-processing
fdi_assignments = {
    (100, 120, 150, 180): 11,
    (160, 125, 210, 185): 12,
    (300, 130, 350, 190): 13,
    (400, 135, 450, 195): 14,
}

# Load a sample image (replace with your dental image)
# Example: img = cv2.imread("dental_xray.png")
img = 255 * np.ones((300, 500, 3), dtype=np.uint8)  # dummy white image

# Convert BGR to RGB for plotting
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

fig, ax = plt.subplots(1, figsize=(10, 6))
ax.imshow(img_rgb)

# Draw bounding boxes with FDI labels
for (x1, y1, x2, y2), _ in detections:
    rect = patches.Rectangle(
        (x1, y1), x2 - x1, y2 - y1,
        linewidth=2, edgecolor='blue', facecolor='none'
    )
    ax.add_patch(rect)

    # Add FDI number (from post-processing dict)
    fdi_id = fdi_assignments.get((x1, y1, x2, y2), "?")
    ax.text(
        x1, y1 - 10, str(fdi_id),
        fontsize=12, color='red', fontweight='bold',
        bbox=dict(facecolor='yellow', alpha=0.6, edgecolor='none')
    )

plt.axis("off")
plt.show()

